{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxicity\n",
    "\n",
    "<p><a name=\"sections\"></a></p>\n",
    "\n",
    "\n",
    "## Sections\n",
    "\n",
    "- <a href=\"#Initialization\">Initialization</a><br>\n",
    "- <a href=\"#Data-preparation\">Data preparation</a><br>\n",
    "    - <a href=\"#Import-the-data\">Import the data</a><br>\n",
    "    - <a href=\"#Formatting\">Formatting</a><br>\n",
    "    - <a href=\"#Detour---Shouting\">Detour - Shouting</a><br>\n",
    "- <a href=\"#Classification\">Classification</a><br>\n",
    "    - <a href=\"#Feature-sets\">Feature sets</a><br>\n",
    "    - <a href=\"#Training\">Training</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data\n",
    "\n",
    "Import the data from csv file and print the first 5 records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data from csv, print the dimensions and view the first 5 records\n",
    "df = pd.read_csv(filepath_or_buffer='./data/train.csv')\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.095844\n",
       "severe_toxic     0.009996\n",
       "obscene          0.052948\n",
       "threat           0.002996\n",
       "insult           0.049364\n",
       "identity_hate    0.008805\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the frequency of each class label\n",
    "df.iloc[:, 2:].sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice that there are 6 different classification labels in the dataset. For this project I am going to focus on predicting only 2 of the 6 different class labels. The other team members will focus on the remaining 4 class labels. I will focus only on **obscene** and **threat**. In order to do this I will remove unwanted columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first prepare the data.\n",
    "\n",
    "+ Drop redundant columns\n",
    "+ Remove unknown ascii characters\n",
    "+ Some comments contains a timestamp and/or IP address. Replace those with a single space\n",
    "+ Remove automated comment\n",
    "+ Remove unwanted characters\n",
    "+ Replace multiple spaces with a single space\n",
    "+ Remove words that are shorter than 3 characters long\n",
    "+ Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant columns\n",
    "df.drop(['id', 'toxic', 'severe_toxic', 'insult', 'identity_hate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions to be used to format the comments\n",
    "# handle non-asci characters \n",
    "def handle_unknown(s):\n",
    "    return s.strip().decode(\"ascii\",\"ignore\").encode(\"ascii\")\n",
    "\n",
    "# handle ip addresses\n",
    "def handle_ip(s):\n",
    "    return re.sub('[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+', ' ', s ).strip()\n",
    "\n",
    "# handle timestamps\n",
    "def handle_ts(s):\n",
    "    return re.sub('[0-9]{1,2}:[0-9]{1,2}.+,\\s.+,\\s[0-9]{4}\\s+\\([A-Z]+\\)', ' ', s ).strip()\n",
    "\n",
    "# handle automated comments\n",
    "def handle_autocomment(s):\n",
    "    return re.sub('The preceding unsigned comment was added by', ' ', s ).strip()\n",
    "\n",
    "# handle multiple spaces\n",
    "def handle_spaces(s):\n",
    "    return re.sub('\\s+', ' ', s ).strip()\n",
    "\n",
    "# remove punctuation\n",
    "def handle_punc(s):\n",
    "    return re.sub(\"[^A-z\\s]\", ' ', s).strip()\n",
    "\n",
    "# split each comment into a list of words\n",
    "def handle_split(s):\n",
    "    return s.split()\n",
    "\n",
    "# keep only words where length >= 3\n",
    "def handle_remove(s):\n",
    "    return [e for e in s if len(e) >= 3]\n",
    "\n",
    "# wrapping the above into one func for preformance sake\n",
    "def handler(s):\n",
    "    return handle_remove(handle_split(handle_spaces(handle_punc(handle_autocomment(handle_ts(handle_ip(handle_unknown(s))))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create before and after variables to display the effect of the changes\n",
    "before = df['comment_text'][37]\n",
    "df['comment_text'] = df['comment_text'].apply(handler)\n",
    "after = df['comment_text'][37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretty much everyone from warren county/surrounding regions was born at glens falls hospital. myself included. however, i'm not sure this qualifies anyone as being a glens falls native. rachel ray is, i believe, actually from the town of lake luzerne.  —The preceding unsigned comment was added by 70.100.229.154  04:28:57, August 19, 2007 (UTC)\n"
     ]
    }
   ],
   "source": [
    "# print before\n",
    "print before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretty', 'much', 'everyone', 'from', 'warren', 'county', 'surrounding', 'regions', 'was', 'born', 'glens', 'falls', 'hospital', 'myself', 'included', 'however', 'not', 'sure', 'this', 'qualifies', 'anyone', 'being', 'glens', 'falls', 'native', 'rachel', 'ray', 'believe', 'actually', 'from', 'the', 'town', 'lake', 'luzerne']\n"
     ]
    }
   ],
   "source": [
    "# print after\n",
    "print after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the prinouts of *before* and *after* we can see how the changes have been applied correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour - Shouting\n",
    "Measure shouting using the number of UPPERCASE words in a comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function that return the number of words uppercase that are uppercase as a ratio\n",
    "def ratio_uppers(l):\n",
    "    return round(float(sum(i.isupper() for i in l))/len(l), ndigits=3) if len(l) > 0 else 0\n",
    "\n",
    "# add new column which measure the degree of shouting\n",
    "df['shouting'] = df['comment_text'].apply(ratio_uppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>shouting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[COCKSUCKER, BEFORE, YOU, PISS, AROUND, WORK]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[FUCK, YOUR, FILTHY, MOTHER, THE, ASS, DRY]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[GET, FUCKED, GET, FUCKEEED, GOT, DRINK, THAT,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>[UNBLOCK, GET, LAWYERS, YOU, FOR, BLOCKING, CO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>[new, userbox, TABTAB, TABTAB, White, TABTAB, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>[UTC, December]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>[MATT, HARDY, FUCKY, Italic, text[[Media, Exam...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>[THIS, WIIL, LAST, USE, THIS, ACOUNT, PLEASE, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>[PAGE, TRIED, CREATE, NOW, ACTUAL, PAGE, LOL, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>[Thank, you, for, your, RACIST, experimenting,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>[NEVER, FUCKING, MADE, THIS, MOTHER, FUCKING, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>[HELLO, HOW, GET, SOMEBODY, FIX, SHIT, AROUND,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>[DISLIKE, RACISM, AND, CAN, SEE, THAT, YOU, HA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>[WASNT, VANDALISM, DICKHEAD]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>[those, pushing, anti, MRM, POV]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>[AMBER, TAYLOR, FOREVER, AMBER, TAYLOR, FOREVER]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>[How, astute, remember, civility, the, key, Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>[WILL, MOTHERFUCKING, SAFETY, GUARANTEED, FUCK...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>[LIKES, ITIN, THE, ASS, MUHAMAD, ALI, AND, KEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>[Aug, UTC]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>[GET, LIFE, YOU, PRICK]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>[Why, are, you, changing, the, SOMALI, PEOPLE,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>[WOULDN, THE, FIRST, TIME, BITCH, FUCK, YOU, F...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>[How, about, this, FUCK, YOURSELF]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>[JESUS, CHIRST, HELP, GOT, BLOCKED]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>[This, your, Dad, sam, worried, about, you, Wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>[reliable, source, your, reference, DOESNT, EV...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>[SHUT, YOU, FAT, POOP, WILL, KICK, YOUR, ASS]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>[GAY, Love, GAY, Love, GAY, Love]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>[KISS, DICK, ALL, YOU]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157941</th>\n",
       "      <td>[WIKIPEDIA, THE, OPPOSITE, STRAIGHT, WIKIPEDIA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158012</th>\n",
       "      <td>[HAVE, THOUSANDS, IPS, CAN, THIS, ALL, DAY, KE...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158027</th>\n",
       "      <td>[WHO, WAS, EXECUTED, HENRY, VII, ANSWER, NOW]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158029</th>\n",
       "      <td>[all, link, [[WP, LEAD]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158146</th>\n",
       "      <td>[This, your, last, warning, WARNING, RESPOND, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158178</th>\n",
       "      <td>[per, COMMONNAME]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158211</th>\n",
       "      <td>[WAS, METAPHORICAL, BLOCKHEAD, SENSE, WAS, ALS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158273</th>\n",
       "      <td>[SHUT, AND, LEAVE, ALONE, FAGGOT, SHUT, AHEAD,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158407</th>\n",
       "      <td>[Apr, UTC]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158454</th>\n",
       "      <td>[HATE, TURKS, LOT, MAYBE, ONE, DAY, THERE, WIL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158556</th>\n",
       "      <td>[HEY, BET, YOU, THOUGHT, YOU, BANNED, LAST, TI...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158570</th>\n",
       "      <td>[STOP, POSTING, WARNIGN, TALK, PAGE, ITS, FUCK...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158589</th>\n",
       "      <td>[RIGHT, vanish]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158809</th>\n",
       "      <td>[HOW, CAN, JUDGE, SPORT, PERSONALITY, JUST, TH...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158951</th>\n",
       "      <td>[FUCK, YOU, BARACK, OBAMA, MUSLIM, SUCKS, ASS]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158988</th>\n",
       "      <td>[YES, understand, YES, YES, YES]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159063</th>\n",
       "      <td>[PLEASE, JUST, LITTLE, REASEARCH, AND, STOD, R...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159069</th>\n",
       "      <td>[You, suck, bitch, DOYLE, RULES]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159070</th>\n",
       "      <td>[DOWN, WITH, THE, USA]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159103</th>\n",
       "      <td>[DEAR, DEAR, HOW, FUKIN, SAD, WILL, REGRET, TH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159197</th>\n",
       "      <td>[ADD, TERRAIN, MORVAL, TRANS]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159220</th>\n",
       "      <td>[CARTERNUT, SHALL, NEVER, BANNED, ALF]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159278</th>\n",
       "      <td>[THE, ARTICLE, TITLED, THE, ELLIOTT, ARGUMENT,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159330</th>\n",
       "      <td>[LOVE, KATILYN, JEWELL]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159378</th>\n",
       "      <td>[AHEAD, AND, FUCKING, BAN, LIKE, THAT, WILL, H...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159413</th>\n",
       "      <td>[PMR, was, simply, renamed, RCP]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159493</th>\n",
       "      <td>[FUCKING, FAGGOT, LOLWAT]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159514</th>\n",
       "      <td>[YOU, ARE, MISCHIEVIOUS, PUBIC, HAIR]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159520</th>\n",
       "      <td>[HEY, HOW, ABOUT, SHE, PUTS, OUT, NEW, SINGLE,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159549</th>\n",
       "      <td>[UTC, Mar]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3085 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  obscene  threat  \\\n",
       "6           [COCKSUCKER, BEFORE, YOU, PISS, AROUND, WORK]        1       0   \n",
       "43            [FUCK, YOUR, FILTHY, MOTHER, THE, ASS, DRY]        1       0   \n",
       "51      [GET, FUCKED, GET, FUCKEEED, GOT, DRINK, THAT,...        1       0   \n",
       "159     [UNBLOCK, GET, LAWYERS, YOU, FOR, BLOCKING, CO...        0       0   \n",
       "183     [new, userbox, TABTAB, TABTAB, White, TABTAB, ...        0       0   \n",
       "281                                       [UTC, December]        0       0   \n",
       "324     [MATT, HARDY, FUCKY, Italic, text[[Media, Exam...        1       0   \n",
       "338     [THIS, WIIL, LAST, USE, THIS, ACOUNT, PLEASE, ...        0       0   \n",
       "369     [PAGE, TRIED, CREATE, NOW, ACTUAL, PAGE, LOL, ...        0       0   \n",
       "415     [Thank, you, for, your, RACIST, experimenting,...        1       0   \n",
       "437     [NEVER, FUCKING, MADE, THIS, MOTHER, FUCKING, ...        1       0   \n",
       "520     [HELLO, HOW, GET, SOMEBODY, FIX, SHIT, AROUND,...        1       0   \n",
       "610     [DISLIKE, RACISM, AND, CAN, SEE, THAT, YOU, HA...        0       0   \n",
       "632                          [WASNT, VANDALISM, DICKHEAD]        1       0   \n",
       "725                      [those, pushing, anti, MRM, POV]        0       0   \n",
       "728      [AMBER, TAYLOR, FOREVER, AMBER, TAYLOR, FOREVER]        0       0   \n",
       "747     [How, astute, remember, civility, the, key, Th...        0       0   \n",
       "761     [WILL, MOTHERFUCKING, SAFETY, GUARANTEED, FUCK...        1       0   \n",
       "827     [LIKES, ITIN, THE, ASS, MUHAMAD, ALI, AND, KEL...        1       0   \n",
       "829                                            [Aug, UTC]        0       0   \n",
       "831                               [GET, LIFE, YOU, PRICK]        0       0   \n",
       "931     [Why, are, you, changing, the, SOMALI, PEOPLE,...        0       0   \n",
       "1017    [WOULDN, THE, FIRST, TIME, BITCH, FUCK, YOU, F...        1       1   \n",
       "1063                   [How, about, this, FUCK, YOURSELF]        1       0   \n",
       "1078                  [JESUS, CHIRST, HELP, GOT, BLOCKED]        0       0   \n",
       "1159    [This, your, Dad, sam, worried, about, you, Wo...        1       0   \n",
       "1239    [reliable, source, your, reference, DOESNT, EV...        0       0   \n",
       "1312        [SHUT, YOU, FAT, POOP, WILL, KICK, YOUR, ASS]        1       1   \n",
       "1341                    [GAY, Love, GAY, Love, GAY, Love]        0       0   \n",
       "1373                               [KISS, DICK, ALL, YOU]        1       0   \n",
       "...                                                   ...      ...     ...   \n",
       "157941  [WIKIPEDIA, THE, OPPOSITE, STRAIGHT, WIKIPEDIA...        0       0   \n",
       "158012  [HAVE, THOUSANDS, IPS, CAN, THIS, ALL, DAY, KE...        0       0   \n",
       "158027      [WHO, WAS, EXECUTED, HENRY, VII, ANSWER, NOW]        0       0   \n",
       "158029                            [all, link, [[WP, LEAD]        0       0   \n",
       "158146  [This, your, last, warning, WARNING, RESPOND, ...        0       0   \n",
       "158178                                  [per, COMMONNAME]        0       0   \n",
       "158211  [WAS, METAPHORICAL, BLOCKHEAD, SENSE, WAS, ALS...        0       0   \n",
       "158273  [SHUT, AND, LEAVE, ALONE, FAGGOT, SHUT, AHEAD,...        0       0   \n",
       "158407                                         [Apr, UTC]        0       0   \n",
       "158454  [HATE, TURKS, LOT, MAYBE, ONE, DAY, THERE, WIL...        0       0   \n",
       "158556  [HEY, BET, YOU, THOUGHT, YOU, BANNED, LAST, TI...        0       0   \n",
       "158570  [STOP, POSTING, WARNIGN, TALK, PAGE, ITS, FUCK...        1       0   \n",
       "158589                                    [RIGHT, vanish]        0       0   \n",
       "158809  [HOW, CAN, JUDGE, SPORT, PERSONALITY, JUST, TH...        0       0   \n",
       "158951     [FUCK, YOU, BARACK, OBAMA, MUSLIM, SUCKS, ASS]        1       0   \n",
       "158988                   [YES, understand, YES, YES, YES]        0       0   \n",
       "159063  [PLEASE, JUST, LITTLE, REASEARCH, AND, STOD, R...        0       0   \n",
       "159069                   [You, suck, bitch, DOYLE, RULES]        1       0   \n",
       "159070                             [DOWN, WITH, THE, USA]        0       0   \n",
       "159103  [DEAR, DEAR, HOW, FUKIN, SAD, WILL, REGRET, TH...        1       0   \n",
       "159197                      [ADD, TERRAIN, MORVAL, TRANS]        0       0   \n",
       "159220             [CARTERNUT, SHALL, NEVER, BANNED, ALF]        0       0   \n",
       "159278  [THE, ARTICLE, TITLED, THE, ELLIOTT, ARGUMENT,...        0       0   \n",
       "159330                            [LOVE, KATILYN, JEWELL]        0       0   \n",
       "159378  [AHEAD, AND, FUCKING, BAN, LIKE, THAT, WILL, H...        1       0   \n",
       "159413                   [PMR, was, simply, renamed, RCP]        0       0   \n",
       "159493                          [FUCKING, FAGGOT, LOLWAT]        1       0   \n",
       "159514              [YOU, ARE, MISCHIEVIOUS, PUBIC, HAIR]        0       0   \n",
       "159520  [HEY, HOW, ABOUT, SHE, PUTS, OUT, NEW, SINGLE,...        0       0   \n",
       "159549                                         [UTC, Mar]        0       0   \n",
       "\n",
       "        shouting  \n",
       "6          1.000  \n",
       "43         1.000  \n",
       "51         1.000  \n",
       "159        1.000  \n",
       "183        0.375  \n",
       "281        0.500  \n",
       "324        0.600  \n",
       "338        1.000  \n",
       "369        1.000  \n",
       "415        0.561  \n",
       "437        1.000  \n",
       "520        1.000  \n",
       "610        1.000  \n",
       "632        1.000  \n",
       "725        0.400  \n",
       "728        1.000  \n",
       "747        0.360  \n",
       "761        1.000  \n",
       "827        1.000  \n",
       "829        0.500  \n",
       "831        1.000  \n",
       "931        0.783  \n",
       "1017       1.000  \n",
       "1063       0.400  \n",
       "1078       1.000  \n",
       "1159       0.375  \n",
       "1239       0.429  \n",
       "1312       1.000  \n",
       "1341       0.500  \n",
       "1373       1.000  \n",
       "...          ...  \n",
       "157941     1.000  \n",
       "158012     1.000  \n",
       "158027     1.000  \n",
       "158029     0.500  \n",
       "158146     0.500  \n",
       "158178     0.500  \n",
       "158211     1.000  \n",
       "158273     1.000  \n",
       "158407     0.500  \n",
       "158454     1.000  \n",
       "158556     0.409  \n",
       "158570     1.000  \n",
       "158589     0.500  \n",
       "158809     1.000  \n",
       "158951     1.000  \n",
       "158988     0.800  \n",
       "159063     1.000  \n",
       "159069     0.400  \n",
       "159070     1.000  \n",
       "159103     1.000  \n",
       "159197     1.000  \n",
       "159220     1.000  \n",
       "159278     1.000  \n",
       "159330     1.000  \n",
       "159378     0.457  \n",
       "159413     0.400  \n",
       "159493     1.000  \n",
       "159514     1.000  \n",
       "159520     1.000  \n",
       "159549     0.500  \n",
       "\n",
       "[3085 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['shouting'] > (1.0/3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouch! There are some really nasty comments in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the formatting step we need to change all words to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert all values in a list to lowercase\n",
    "def conv_lower(l):\n",
    "    return [i.lower() for i in l]\n",
    "\n",
    "# convert all uppercase to lower case\n",
    "df['comment_text'] = df['comment_text'].apply(conv_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "We are going to classify the comments using the NaiveBayes algorithm that is part of the NLTK library. This library takes a list of tuples as input so some further formatting will be required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary\n",
    "First we need to create a default dictionary with all words and a default flag=False. Then we need create a features set for each **comment** based on this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get ALL the words returned in a dict with default value of false\n",
    "def get_all_words(lists):\n",
    "    d = dict()\n",
    "    for l in lists:\n",
    "        d.update(dict.fromkeys(l, False))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177303"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words as dict\n",
    "all_words = get_all_words(df['comment_text'])\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 177303 unique words. Lets' look at the first 5 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['tsukino', 'sowell', 'woods', 'spiders', 'gavan'],\n",
       "  [False, False, False, False, False])]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(all_words.keys()[:5], all_words.values()[:5])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets\n",
    "Next, we create the feature set for each **comment** using the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert toxic & severe_toxic to strings\n",
    "# df['obscene'] = df['obscene'].apply(lambda i: 'obscene' if i == 1 else 'neutral')\n",
    "# df['threat'] = df['threat'].apply(lambda i: 'threat' if i == 1 else 'neutral')\n",
    "\n",
    "# # create two seperate lists in the correct format for nltk.classify.apply_features to consume\n",
    "# dat_obscene = [tuple(i) for i in zip(df['comment_text'].tolist(), df['obscene'].tolist())]\n",
    "# dat_threat = [tuple(i) for i in zip(df['comment_text'].tolist(), df['threat'].tolist())]\n",
    "\n",
    "# # del df\n",
    "# print len(dat_obscene), len(dat_threat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get features for a comment\n",
    "def extract_features(words):\n",
    "    d = all_words.copy()\n",
    "    d.update(dict.fromkeys(words, True))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_orig = df.copy()\n",
    "df = df_orig.loc[:300].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['obscene'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = [tuple(i) for i in zip(df['comment_text'].tolist(), \\\n",
    "                                  df['obscene'].apply(lambda i: 'obscene' if i == 1 else 'neutral').tolist())]\n",
    "len(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Let's train a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model\n",
    "training_set = nltk.classify.apply_features(extract_features, dat) \n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del training_set, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cocksucker', 'before', 'you', 'piss', 'around', 'work']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat[6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(extract_features(dat[6][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [classifier.classify(extract_features(instance[0][0])) for instance in dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(i != 'obscene' for i in test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene = df[df['obscene'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>shouting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[cocksucker, before, you, piss, around, work]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[you, are, gay, antisemmitian, archangel, whit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[fuck, your, filthy, mother, the, ass, dry]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[get, fucked, get, fuckeeed, got, drink, that,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[stupid, peace, shit, stop, deleting, stuff, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[tony, sidaway, obviously, fistfuckee, loves, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[band, page, deletion, you, thought, was, gone...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[all, edits, are, good, cunts, like, you, who,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>[pair, jew, hating, weiner, nazi, schmucks]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>[think, that, your, fagget, get, oife, and, bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>[you, are, stupid, fuck, and, your, mother, cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>[your, blatant, pov, pushing, neither, you, gu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>[fuck, you, block, you, faggot, pussy]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>[kill, all, niggers, have, hard, that, others,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>[burn, deck, that, guy, burn, deck, like, what...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>[fuck, off, gay, boy, smelly, fuck, mum, poopie]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>[this, user, such, worthless, goddamn, faggot,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>[fuck, off, you, are, not, administrator, you,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comment_text  obscene  threat  \\\n",
       "6        [cocksucker, before, you, piss, around, work]        1       0   \n",
       "42   [you, are, gay, antisemmitian, archangel, whit...        1       0   \n",
       "43         [fuck, your, filthy, mother, the, ass, dry]        1       0   \n",
       "51   [get, fucked, get, fuckeeed, got, drink, that,...        1       0   \n",
       "55   [stupid, peace, shit, stop, deleting, stuff, a...        1       0   \n",
       "56   [tony, sidaway, obviously, fistfuckee, loves, ...        1       0   \n",
       "58   [band, page, deletion, you, thought, was, gone...        1       0   \n",
       "65   [all, edits, are, good, cunts, like, you, who,...        1       0   \n",
       "105        [pair, jew, hating, weiner, nazi, schmucks]        1       0   \n",
       "176  [think, that, your, fagget, get, oife, and, bu...        1       1   \n",
       "181  [you, are, stupid, fuck, and, your, mother, cu...        1       0   \n",
       "201  [your, blatant, pov, pushing, neither, you, gu...        1       0   \n",
       "211             [fuck, you, block, you, faggot, pussy]        1       0   \n",
       "218  [kill, all, niggers, have, hard, that, others,...        1       0   \n",
       "231  [burn, deck, that, guy, burn, deck, like, what...        1       0   \n",
       "238   [fuck, off, gay, boy, smelly, fuck, mum, poopie]        1       0   \n",
       "295  [this, user, such, worthless, goddamn, faggot,...        1       0   \n",
       "298  [fuck, off, you, are, not, administrator, you,...        1       0   \n",
       "\n",
       "     shouting  \n",
       "6       1.000  \n",
       "42      0.000  \n",
       "43      1.000  \n",
       "51      1.000  \n",
       "55      0.000  \n",
       "56      0.000  \n",
       "58      0.000  \n",
       "65      0.000  \n",
       "105     0.000  \n",
       "176     0.000  \n",
       "181     0.000  \n",
       "201     0.075  \n",
       "211     0.000  \n",
       "218     0.000  \n",
       "231     0.000  \n",
       "238     0.000  \n",
       "295     0.000  \n",
       "298     0.154  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_informative_features = (classifier.most_informative_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for (i, j) in most_informative_features if i == 'fuck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
