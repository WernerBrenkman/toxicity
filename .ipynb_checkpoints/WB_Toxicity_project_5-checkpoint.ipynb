{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxicity\n",
    "\n",
    "<p><a name=\"sections\"></a></p>\n",
    "\n",
    "\n",
    "## Sections\n",
    "\n",
    "- <a href=\"#Initialization\">Initialization</a><br>\n",
    "- <a href=\"#Data-preparation\">Data preparation</a><br>\n",
    "    - <a href=\"#Import-the-data\">Import the data</a><br>\n",
    "    - <a href=\"#Formatting\">Formatting</a><br>\n",
    "    - <a href=\"#Detour---Shouting\">Detour - Shouting</a><br>\n",
    "- <a href=\"#Classification\">Classification</a><br>\n",
    "    - <a href=\"#Feature-sets\">Feature sets</a><br>\n",
    "    - <a href=\"#Training\">Training</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data\n",
    "\n",
    "Import the data from csv file and print the first 5 records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data from csv, print the dimensions and view the first 5 records\n",
    "df = pd.read_csv(filepath_or_buffer='./data/train.csv')\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.095844\n",
       "severe_toxic     0.009996\n",
       "obscene          0.052948\n",
       "threat           0.002996\n",
       "insult           0.049364\n",
       "identity_hate    0.008805\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the frequency of each class label\n",
    "df.iloc[:, 2:].sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice that there are 6 different classification labels in the dataset. For this project I am going to focus on predicting only 2 of the 6 different class labels. The other team members will focus on the remaining 4 class labels. I will focus only on **toxic** and **severe_toxic**. In order to do this I will remove unwanted columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first prepare the data before we create a corpus.\n",
    "\n",
    "+ Drop redundant columns\n",
    "+ Remove unknown ascii characters\n",
    "+ Some comments contains a timestamp and/or IP address. Replace those with a single space\n",
    "+ Remove automated comment\n",
    "+ Remove unwanted characters\n",
    "+ Replace multiple spaces with a single space\n",
    "+ Remove words that are shorter than 3 characters long\n",
    "+ Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant columns\n",
    "df.drop(['id', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions to be used to format the comments\n",
    "# handle non-asci characters \n",
    "def handle_unknown(s):\n",
    "    return s.strip().decode(\"ascii\",\"ignore\").encode(\"ascii\")\n",
    "\n",
    "# handle ip addresses\n",
    "def handle_ip(s):\n",
    "    return re.sub('[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9]+', ' ', s ).strip()\n",
    "\n",
    "# handle timestamps\n",
    "def handle_ts(s):\n",
    "    return re.sub('[0-9]{1,2}:[0-9]{1,2}.+,\\s.+,\\s[0-9]{4}\\s+\\([A-Z]+\\)', ' ', s ).strip()\n",
    "\n",
    "# handle automated comments\n",
    "def handle_autocomment(s):\n",
    "    return re.sub('The preceding unsigned comment was added by', ' ', s ).strip()\n",
    "\n",
    "# handle multiple spaces\n",
    "def handle_spaces(s):\n",
    "    return re.sub('\\s+', ' ', s ).strip()\n",
    "\n",
    "# remove punctuation\n",
    "def handle_punc(s):\n",
    "    return re.sub(\"[^A-z\\s]\", ' ', s).strip()\n",
    "\n",
    "# split each comment into a list of words\n",
    "def handle_split(s):\n",
    "    return s.split()\n",
    "\n",
    "# keep only words where length >= 3\n",
    "def handle_remove(s):\n",
    "    return [e for e in s if len(e) >= 3]\n",
    "\n",
    "# wrapping the above into one func for preformance sake\n",
    "def handler(s):\n",
    "    return handle_remove(handle_split(handle_spaces(handle_punc(handle_autocomment(handle_ts(handle_ip(handle_unknown(s))))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create before and after variables to display the effect of the changes\n",
    "before = df['comment_text'][37]\n",
    "df['comment_text'] = df['comment_text'].apply(handler)\n",
    "after = df['comment_text'][37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretty much everyone from warren county/surrounding regions was born at glens falls hospital. myself included. however, i'm not sure this qualifies anyone as being a glens falls native. rachel ray is, i believe, actually from the town of lake luzerne.  â€”The preceding unsigned comment was added by 70.100.229.154  04:28:57, August 19, 2007 (UTC)\n"
     ]
    }
   ],
   "source": [
    "# print before\n",
    "print before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pretty', 'much', 'everyone', 'from', 'warren', 'county', 'surrounding', 'regions', 'was', 'born', 'glens', 'falls', 'hospital', 'myself', 'included', 'however', 'not', 'sure', 'this', 'qualifies', 'anyone', 'being', 'glens', 'falls', 'native', 'rachel', 'ray', 'believe', 'actually', 'from', 'the', 'town', 'lake', 'luzerne']\n"
     ]
    }
   ],
   "source": [
    "# print after\n",
    "print after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the prinouts of *before* and *after* we can see how the changes have been applied correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour - Shouting\n",
    "Measure shouting using the number of UPPERCASE words in a comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function that return the number of words uppercase that are uppercase as a ratio\n",
    "def ratio_uppers(l):\n",
    "    return round(sum(1 for i in l if i.isupper())/len(l), ndigits=3) if len(l) > 0 else 0\n",
    "\n",
    "# add new column which measure the degree of shouting\n",
    "df['shouting'] = df['comment_text'].apply(ratio_uppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>shouting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[COCKSUCKER, BEFORE, YOU, PISS, AROUND, WORK]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[FUCK, YOUR, FILTHY, MOTHER, THE, ASS, DRY]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[GET, FUCKED, GET, FUCKEEED, GOT, DRINK, THAT,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>[UNBLOCK, GET, LAWYERS, YOU, FOR, BLOCKING, CO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>[THIS, WIIL, LAST, USE, THIS, ACOUNT, PLEASE, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comment_text  toxic  severe_toxic  \\\n",
       "6        [COCKSUCKER, BEFORE, YOU, PISS, AROUND, WORK]      1             1   \n",
       "43         [FUCK, YOUR, FILTHY, MOTHER, THE, ASS, DRY]      1             0   \n",
       "51   [GET, FUCKED, GET, FUCKEEED, GOT, DRINK, THAT,...      1             0   \n",
       "159  [UNBLOCK, GET, LAWYERS, YOU, FOR, BLOCKING, CO...      1             0   \n",
       "338  [THIS, WIIL, LAST, USE, THIS, ACOUNT, PLEASE, ...      0             0   \n",
       "\n",
       "     shouting  \n",
       "6         1.0  \n",
       "43        1.0  \n",
       "51        1.0  \n",
       "159       1.0  \n",
       "338       1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['shouting']>0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouch! There are some really nasty comments in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the formatting step we need to change all words to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert all values in a list to lowercase\n",
    "def conv_lower(l):\n",
    "    return [i.lower() for i in l]\n",
    "\n",
    "# convert all uppercase to lower case\n",
    "df['comment_text'] = df['comment_text'].apply(conv_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "We are going to classify the comments using the NaiveBayes algorithm that is part of the NLTK library. This library takes a list of tuples as input so some further formatting will be required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets\n",
    "We need to build two lists, one for training and one for testing by converting the dataframe **df** to two seperate lists, one for **toxic** and the other for **severe_toxic** comments. These lists should be lists of tuples in this format (list of words, class label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert toxic & severe_toxic to strings\n",
    "df['tox'] = df['toxic'].apply(lambda i: 'toxic' if i == 1 else 'neutral')\n",
    "df['sev_tox'] = df['severe_toxic'].apply(lambda i: 'severe_toxic' if i == 1 else 'neutral')\n",
    "# drop redundant cols\n",
    "df.drop(['toxic', 'severe_toxic'], axis=1, inplace=True)\n",
    "\n",
    "# create two seperate lists in the correct format for nltk.classify.apply_features to consume\n",
    "dat_tox = [tuple(i) for i in zip(df['comment_text'].tolist(), df['tox'].tolist())]\n",
    "dat_sev_tox = [tuple(i) for i in zip(df['comment_text'].tolist(), df['sev_tox'].tolist())]\n",
    "\n",
    "del df\n",
    "print len(dat_tox), len(dat_sev_tox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get ALL the words returned in a dict with default value of false\n",
    "def get_all_words(lists):\n",
    "    d = dict()\n",
    "    for l in lists:\n",
    "        d.update(dict.fromkeys(l, False))\n",
    "    return d\n",
    "\n",
    "# function to get features for a comment\n",
    "def extract_features(words):\n",
    "    d = all_words.copy()\n",
    "    d.update(dict.fromkeys(words, True))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a default dictionary, that we will use later when creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177303"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words as dict\n",
    "all_words = get_all_words(df['comment_text'])\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 'features' column in the dataframe. This is basically a dictionary for each observation stating which of the the words in **all_words** is present in the comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = df['comment_text'][37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = extract_features(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['myself']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:5].copy()\n",
    "x['features'] = x['comment_text'].apply(extract_features)\n",
    "x['toxic'][2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x['features'].tolist()\n",
    "response = x['toxic'].tolist()\n",
    "dat = zip(features, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [tuple(i) for i in dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(T[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
